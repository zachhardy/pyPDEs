{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import Figure, Axes\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "from pyROMs.pod import POD\n",
    "from readers import NeutronicsDatasetReader\n",
    "\n",
    "from utils import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define Routines"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def cross_validation(dataset: \"NeutronicsDatasetReader\", pod: \"POD\",\n",
    "                     n_splits: int = 5, n_repeats: int = 100,\n",
    "                     interior_only: bool = False, vars: str = None):\n",
    "    \"\"\"\n",
    "    Cross-validation study.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : NeutronicsDatasetReader\n",
    "        The dataset reader containing the data.\n",
    "    pod : POD\n",
    "        The POD model with the appropriate hyper-parameters.\n",
    "    n_splits : int, default 5\n",
    "        The number of splits for the cross-validation study.\n",
    "    n_repeats : int, defualt 100\n",
    "        The number of k-fold repeats.\n",
    "    interior_only : bool, default False\n",
    "        A flag to include only interior values in the validation set.\n",
    "    vars : str, default None\n",
    "        The variables to include in the study.\n",
    "    \"\"\"\n",
    "    # Generate data\n",
    "    X = dataset.create_dataset_matrix(vars)\n",
    "    Y = dataset.parameters\n",
    "\n",
    "    # Storage\n",
    "    means, maxs, mins = [], [], []\n",
    "    construction, query = [], []\n",
    "\n",
    "    # Define cross-validator\n",
    "    cv = RepeatedKFold(n_splits=n_splits, n_repeats=n_repeats)\n",
    "    if interior_only:\n",
    "        interior = dataset.interior_map\n",
    "        iterator = cv.split(X[interior], Y[interior])\n",
    "    else:\n",
    "        iterator = cv.split(X, Y)\n",
    "\n",
    "    # Start cross-validations\n",
    "    for train, test in iterator:\n",
    "        if interior_only:\n",
    "            X_train, Y_train = X[interior][train], Y[interior][train]\n",
    "            X_test, Y_test = X[interior][test], Y[interior][test]\n",
    "            X_train = np.vstack((X_train, X[dataset.boundary_map]))\n",
    "            Y_train = np.vstack((Y_train, Y[dataset.boundary_map]))\n",
    "        else:\n",
    "            X_train, Y_train = X[train], Y[train]\n",
    "            X_test, Y_test = X[test], Y[test]\n",
    "\n",
    "        # Construct ROM\n",
    "        t_start = time.time()\n",
    "        pod.fit(X_train, Y_train)\n",
    "        t_end = time.time()\n",
    "        construction.append(t_end - t_start)\n",
    "\n",
    "        # Make predictions\n",
    "        t_start = time.time()\n",
    "        X_pod = pod.predict(Y_test)\n",
    "        t_end = time.time()\n",
    "        query.append(t_end - t_start)\n",
    "\n",
    "        # Compute errors\n",
    "        errors = np.zeros(len(X_pod))\n",
    "        for i in range(len(X_pod)):\n",
    "            errors[i] = norm(X_test[i] - X_pod[i]) / norm(X_test[i])\n",
    "        means.append(np.mean(errors))\n",
    "        maxs.append(np.max(errors))\n",
    "        mins.append(np.min(errors))\n",
    "\n",
    "    print()\n",
    "    print(f\"{'Number of POD Modes:':<30}\\t{pod.n_modes}\")\n",
    "    print(f\"{'Number of Snapshots:':<30}\\t{pod.n_snapshots}\")\n",
    "    print(f\"{'Number of Validations:':<30}\\t{len(X_pod)}\")\n",
    "    print(f\"{'Avg Construction Time:':<30}\\t{np.mean(construction):.3e} s\")\n",
    "    print(f\"{'Avg Query Time':<30}\\t{np.mean(query):.3e} s\")\n",
    "    print_statistics(means, maxs, mins)\n",
    "    return means, maxs, mins\n",
    "\n",
    "\n",
    "def print_statistics(means, maxs, mins):\n",
    "    \"\"\"\n",
    "    Print the statistics corresponding to the error distributions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    means : list of float\n",
    "    maxs : list of float\n",
    "    mins : list of float\n",
    "    \"\"\"\n",
    "\n",
    "    mean_95conf = np.percentile(means, [2.5, 97.5])\n",
    "    max_95conf = np.percentile(maxs, [2.5, 97.5])\n",
    "    min_95conf = np.percentile(mins, [2.5, 97.5])\n",
    "\n",
    "    print()\n",
    "    print(f\"Mean Error Statistics:\")\n",
    "    print(f\"\\tMean:\\t{np.mean(means):.3e}\")\n",
    "    print(f\"\\tMedian:\\t{np.median(means):.3e}\")\n",
    "    print(f\"\\t95% CI:\\t[{mean_95conf[0]:.3e}, {mean_95conf[1]:.3e}]\")\n",
    "    print(\"\\nMaximum Error Statistics:\")\n",
    "    print(f\"\\tMean:\\t{np.mean(maxs):.3e}\")\n",
    "    print(f\"\\tMedian:\\t{np.median(maxs):.3e}\")\n",
    "    print(f\"\\t95% CI:\\t[{max_95conf[0]:.3e}, {max_95conf[1]:.3e}]\")\n",
    "    print(\"\\nMinimum Error Statistics:\")\n",
    "    print(f\"\\tMean:\\t{np.mean(mins):.3e}\")\n",
    "    print(f\"\\tMedian:\\t{np.median(mins):.3e}\")\n",
    "    print(f\"\\t95% CI:\\t[{min_95conf[0]:.3e}, {min_95conf[1]:.3e}]\")\n",
    "\n",
    "\n",
    "def plot_distributions(means, maxs):\n",
    "    \"\"\"\n",
    "    Plot the mean and max error distributions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    means : list of float\n",
    "    maxs : list of float\n",
    "    \"\"\"\n",
    "    fig: Figure = plt.figure()\n",
    "    for i in range(2):\n",
    "        data = means if i == 0 else maxs\n",
    "        xlabel = \"Mean\" if i == 0 else \"Maximum\"\n",
    "        ylabel = \"Probability\" if i == 0 else \"\"\n",
    "\n",
    "        ax: Axes = fig.add_subplot(1, 2, i + 1)\n",
    "        ax.tick_params(labelsize=12)\n",
    "        ax.set_xlabel(f\"{xlabel} Error\", fontsize=14)\n",
    "        ax.set_ylabel(ylabel, fontsize=14)\n",
    "        ax.grid(True)\n",
    "        sb.histplot(data, bins=20, stat='probability', kde=True,\n",
    "                    log_scale=True, ax=ax)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def print_general_table(means, maxs, mins):\n",
    "    \"\"\"\n",
    "    Print a LaTeX table describing general information about the\n",
    "    cross-validation study.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    means : list of float\n",
    "    maxs : list of float\n",
    "    \"\"\"\n",
    "    msg = \"\\\\begin{tabular}{|c|c|}\"\n",
    "    msg += \"\\n\\t\\hline\"\n",
    "    msg += \"\\n\\t\\\\textbf{Quantity} & \\\\textbf{Value} \\\\\\\\ \\hline\\hline\"\n",
    "    msg += f\"\\n\\tMean of Set Means & {np.mean(means):.3e} \\\\\\\\ \\hline\"\n",
    "    msg += f\"\\n\\tMaximum of Set Means & {np.max(means):.3e} \\\\\\\\ \\hline\"\n",
    "    msg += f\"\\n\\tMinimum of Set Means & {np.min(means):.3e} \\\\\\\\ \\hline\"\n",
    "    msg += f\"\\n\\tMean of Set Maximums & {np.mean(maxs):.3e} \\\\\\\\ \\hline\"\n",
    "    msg += f\"\\n\\tMaximum of Set Maximums & {np.max(maxs):.3e} \\\\\\\\ \\hline\"\n",
    "    msg += f\"\\n\\tMean of Set Minimums & {np.mean(mins):.3e} \\\\\\\\ \\hline\"\n",
    "    msg += f\"\\n\\tMinimum of Set Minimums & {np.min(mins):.3e} \\\\\\\\ \\hline\"\n",
    "    msg += f\"\\n\\end{{tabular}}\"\n",
    "    print(msg)\n",
    "\n",
    "\n",
    "def print_statistics_table(means, maxs):\n",
    "    \"\"\"\n",
    "    Print a LaTeX table.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    means : list of float\n",
    "    maxs : list of float\n",
    "    \"\"\"\n",
    "    conf_mean = np.percentile(means, [2.5, 97.5])\n",
    "    conf_max = np.percentile(maxs, [2.5, 97.5])\n",
    "\n",
    "    msg = \"\\\\begin{tabular}{|c|c|c|}\"\n",
    "    msg += \"\\n\\t\\hline \\\\textbf{Quantity} & \\\\textbf{Mean Error} & \" \\\n",
    "           \"\\\\textbf{Max Error} \\\\\\\\ \\hline\"\n",
    "    msg += f\"\\n\\tMean & {np.mean(means):.3e} & \" \\\n",
    "           f\"{np.mean(maxs):.3e} \\\\\\\\ \\hline\"\n",
    "    msg += f\"\\n\\tStd. Deviation & {np.std(means):.3e} & \" \\\n",
    "           f\"{np.std(maxs):.3e} \\\\\\\\ \\hline\"\n",
    "    msg += f\"\\n\\tMedian & {np.median(means):.3e} & \" \\\n",
    "           f\"{np.median(maxs):.3e} \\\\\\\\ \\hline\"\n",
    "    msg += f\"\\n\\t95\\% Conf. Interval & [{conf_mean[0]:.3e}, {conf_mean[1]:.3e}] & \" \\\n",
    "           f\"[{conf_max[0]:.3e}, {conf_max[1]:.3e}] \\\\\\\\ \\hline\"\n",
    "    msg += f\"\\n\\end{{tabular}}\"\n",
    "    print()\n",
    "    print(msg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Parse the Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and formating the data...\n",
      "Loading the data took 13.387334 s\n"
     ]
    }
   ],
   "source": [
    "problem_name = input(\"What problem? \")\n",
    "\n",
    "print(\"Loading and formating the data...\")\n",
    "t_start = time.time()\n",
    "dataset = get_data(problem_name)\n",
    "t_end = time.time()\n",
    "print(f\"Loading the data took {t_end - t_start:3f} s\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "KFold Cross Validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'interpolation_method'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/2f/k9j6f9l54nvddjrct25wv8sh0000gn/T/ipykernel_444/3711407782.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0mepsilon\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mparams\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"epsilon\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m pod = POD(svd_rank=svd_rank,\n\u001B[0m\u001B[1;32m     12\u001B[0m           \u001B[0minterpolation_method\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minterp\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m           epsilon=epsilon)\n",
      "\u001B[0;31mTypeError\u001B[0m: __init__() got an unexpected keyword argument 'interpolation_method'"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "n_repeats = 500 // n_splits\n",
    "interior_only = False\n",
    "\n",
    "params = get_params(problem_name)\n",
    "vars = params[\"vars\"]\n",
    "svd_rank = 1.0 - params[\"tau\"]\n",
    "interp = params[\"interp\"]\n",
    "epsilon = params[\"epsilon\"]\n",
    "\n",
    "pod = POD(svd_rank=svd_rank,\n",
    "          interpolation_method=interp,\n",
    "          epsilon=epsilon)\n",
    "\n",
    "res = cross_validation(dataset, pod, n_splits,\n",
    "                       n_repeats, interior_only, vars)\n",
    "means, maxs, mins = res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "plot_distributions(means, maxs)\n",
    "print_statistics_table(means, maxs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}